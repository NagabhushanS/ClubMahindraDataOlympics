{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import datetime\n",
    "import pickle\n",
    "from lightgbm import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.base import clone\n",
    "import scipy\n",
    "from sklearn.metrics import *\n",
    "from catboost import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.linear_model import *\n",
    "from xgboost import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.neural_network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X1, y1 ----> 45 features data\n",
    "# X2, y2 -----> dummy of 45 features\n",
    "# X3, y3 -----> 74 features data\n",
    "# X4, y4 -----> new member based 226 features\n",
    "# x5, y5 -----> new cat features without any label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[X1, y1, XTest1, testIds1, featureColumns1, groups1] = pickle.load(open('freshPickles/cleanExperimentDataF=45.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[X2, y2, XTest2, testIds2, featureColumns2, groups2] = pickle.load(open('freshPickles/dummyCleanExperimentData.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[X3, y3, XTest3, testIds3, featureColumns3, groups3] = pickle.load(open('freshPickles/cleanExperimentDataF=74.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[X4, y4, XTest4, testIds4, featureColumns4, groups4] = pickle.load(open('freshPickles/cleanExperimentDataF=226.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[trainDF5, testDF5, y5, testIds5, groups5] = pickle.load(open('freshPickles/catFeaturesdtypecat.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gfCV5 = list(GroupKFold(n_splits=5).split(X1, y1, groups1))\n",
    "gfCV10 = list(GroupKFold(n_splits=10).split(X1, y1, groups1))\n",
    "gfCV20 = list(GroupKFold(n_splits=20).split(X1, y1, groups1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCrossValPredict(baseModel, X, y, XTest, cv):\n",
    "    trainCVP = np.zeros((X.shape[0], ))\n",
    "    testCVP = np.zeros((XTest.shape[0], ))\n",
    "    i=0\n",
    "    for ti, vi in cv:\n",
    "        print(\"fold \"+str(i)+'...')\n",
    "        model = clone(baseModel)\n",
    "        model.fit(X[ti], y[ti])\n",
    "        trainCVP[vi] = model.predict(X[vi])\n",
    "        testCVP += model.predict(XTest)\n",
    "        i+=1\n",
    "    testCVP/=5\n",
    "    return trainCVP, testCVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCrossValPredictForDF(baseModel, X, y, XTest, cv):\n",
    "    trainCVP = np.zeros((X.shape[0], ))\n",
    "    testCVP = np.zeros((XTest.shape[0], ))\n",
    "    i=0\n",
    "    for ti, vi in cv:\n",
    "        print(\"fold \"+str(i)+'...')\n",
    "        model = clone(baseModel)\n",
    "        model.fit(X.iloc[ti], y[ti])\n",
    "        trainCVP[vi] = model.predict(X.iloc[vi])\n",
    "        testCVP += model.predict(XTest)\n",
    "        i+=1\n",
    "    testCVP/=5\n",
    "    return trainCVP, testCVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp1 = {'num_leaves': 48, 'subsample_freq': 8, 'colsample_bytree': 0.52, 'max_depth': 16, 'learning_rate': 0.05, 'min_child_weight': 0.001, 'min_split_gain': 0.05, 'n_estimators': 497, 'subsample': 0.92, 'random_state': 7, 'min_child_samples': 20}\n",
    "pp2 = {'num_leaves': 195, 'subsample_freq': 1, 'colsample_bytree': 0.69, 'max_depth': 7, 'learning_rate': 0.05, 'min_child_weight': 0.001, 'min_split_gain': 0.03, 'n_estimators': 325, 'subsample': 0.61, 'random_state': 7, 'min_child_samples': 50}\n",
    "pp3 = {'rsm': 0.72, 'model_size_reg': 0.1, 'learning_rate': 0.05, 'leaf_estimation_method': 'Newton', 'depth': 9, 'random_state': 145, 'iterations': 936, 'l2_leaf_reg': 3, 'od_wait': 15, 'one_hot_max_size': 2, 'max_ctr_complexity': 5, 'bagging_temperature': 1}\n",
    "pp5 = {'num_leaves': 43, 'subsample_freq': 5, 'colsample_bytree': 0.6, 'max_depth': 15, 'learning_rate': 0.07, 'min_child_weight': 0.003, 'min_split_gain': 0, 'n_estimators': 257, 'subsample': 0.68, 'random_state': 7, 'min_child_samples': 40}\n",
    "pp6 = {'rsm': 0.94, 'model_size_reg': 0.0, 'learning_rate': 0.03, 'leaf_estimation_method': 'Newton', 'depth': 11, 'random_state': 523, 'iterations': 558, 'l2_leaf_reg': 2, 'od_wait': 17, 'one_hot_max_size': 5, 'max_ctr_complexity': 5, 'bagging_temperature': 1.6}  \n",
    "pp8 = {'num_leaves': 76, 'subsample_freq': 3, 'colsample_bytree': 0.65, 'max_depth': 5, 'learning_rate': 0.05, 'min_child_weight': 0.001, 'min_split_gain': 0.01, 'n_estimators': 273, 'subsample': 0.75, 'random_state': 2019, 'min_child_samples': 20}\n",
    "\n",
    "model1 = LGBMRegressor(n_jobs=-1, **pp1) #lgbm for 45 f\n",
    "model2 = LGBMRegressor(n_jobs=-1, **pp2) #lgbm for dummy 45 f\n",
    "model3 = CatBoostRegressor(silent=True, **pp3) #catboost for 45 f\n",
    "model4 = LGBMRegressor(n_jobs=-1, random_state=7) #lgbm for new 226 f\n",
    "model5 = LGBMRegressor(n_jobs=-1, **pp5) #lgbm for 74 f\n",
    "model6 = CatBoostRegressor(**pp6) #catboost for 74 f\n",
    "# model7 = CatBoostRegressor(cat_features = **pp6) #catboost for 74 f with cat_features\n",
    "model8 = LGBMRegressor(n_jobs=-1, **pp8)\n",
    "model9 = MLPRegressor(hidden_layer_sizes=(32, 8), random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV1, teCV1 = getCrossValPredict(model1, X1, y1, XTest1, cv=gfCV5) #lgbm for 45 f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV2, teCV2 = getCrossValPredict(model2, X2, y2, XTest2, cv=gfCV5) #lgbm for dummy 45 f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV3, teCV3 = getCrossValPredict(model3, X1, y1, XTest1, cv=gfCV5) #catboost for 45 f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV4, teCV4 = getCrossValPredict(model4, X4, y4, XTest4, cv=gfCV5) #catboost for 45 f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV5, teCV5 = getCrossValPredict(model5, X3, y3, XTest3, cv=gfCV5) #lgbm for 74 f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV6, teCV6 = getCrossValPredict(model6, X3, y3, XTest3, cv=gfCV5) #catboost for 74 f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV8, teCV8 = getCrossValPredictForDF(model8, trainDF5, y5, testDF5, cv=gfCV5) #lgbm fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trCV9, teCV9 = getCrossValPredict(model9, X3, y3, XTest3, cv=gfCV5) #lgbm fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2XTrain = np.hstack((trCV1.reshape((-1, 1)), trCV2.reshape((-1, 1)), trCV3.reshape((-1, 1)), trCV4.reshape((-1, 1)), trCV5.reshape((-1, 1)), trCV6.reshape((-1, 1)), trCV8.reshape((-1, 1))))\n",
    "l2XTest = np.hstack((teCV1.reshape((-1, 1)), teCV2.reshape((-1, 1)), teCV3.reshape((-1, 1)), teCV4.reshape((-1, 1)), teCV5.reshape((-1, 1)), teCV6.reshape((-1, 1)), teCV8.reshape((-1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2Models = [\n",
    "    [RandomForestRegressor(n_jobs=-1, random_state=7), X1, y1, XTest1],\n",
    "    [ExtraTreesRegressor(n_jobs=-1, random_state=7), X1, y1, XTest1],\n",
    "    [sgd, X1, y1, XTest1],\n",
    "    [XGBRegressor(n_jobs=-1, random_state=7), X1, y1, XTest1],\n",
    "    [AdaBoostRegressor(random_state=7), X1, y1, XTest1],\n",
    "    [GradientBoostingRegressor(random_state=7), X1, y1, XTest1],\n",
    "    [DecisionTreeRegressor(random_state=7), X1, y1, XTest1],\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "pickle.dump([l2XTrain, l2XTest], open('freshPickles/'+'l2ModelData'+str(i)+'.pk', 'wb'))\n",
    "for model, X, y, XTest in l2Models:\n",
    "    i+=1\n",
    "    print(model)\n",
    "    trCV, teCV = getCrossValPredict(model, X, y, XTest, cv=gfCV5)\n",
    "    l2XTrain = np.hstack((l2XTrain, trCV.reshape((-1, 1))))\n",
    "    l2XTest = np.hstack((l2XTest, teCV.reshape((-1, 1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2Models = [\n",
    "    [RandomForestRegressor(n_jobs=-1, random_state=7), X2, y2, XTest2],\n",
    "    [ExtraTreesRegressor(n_jobs=-1, random_state=7), X2, y2, XTest2],\n",
    "    [sgd, X2, y2, XTest2],\n",
    "    [XGBRegressor(n_jobs=-1, random_state=7), X2, y2, XTest2],\n",
    "    [AdaBoostRegressor(random_state=7), X2, y2, XTest2],\n",
    "    [GradientBoostingRegressor(random_state=7), X2, y2, XTest2],\n",
    "    [DecisionTreeRegressor(random_state=7), X2, y2, XTest2],\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for model, X, y, XTest in l2Models:\n",
    "    i+=1\n",
    "    print(model)\n",
    "    trCV, teCV = getCrossValPredict(model, X, y, XTest, cv=gfCV5)\n",
    "    l2XTrain = np.hstack((l2XTrain, trCV.reshape((-1, 1))))\n",
    "    l2XTest = np.hstack((l2XTest, teCV.reshape((-1, 1))))\n",
    "    pickle.dump([l2XTrain, l2XTest], open('freshPickles/'+'l2ModelData'+str(i)+'.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyRandomSearch:\n",
    "    def __init__(self, niter, cv, scoring, model, fileName, params):\n",
    "        self.niter=niter;\n",
    "        self.model = model\n",
    "        self.cv=cv\n",
    "        self.scoring = scoring\n",
    "        self.logger = open(fileName, 'a')\n",
    "        self.params = params\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for z in range(self.niter):\n",
    "            pp = {}\n",
    "            for key in self.params:\n",
    "                ri = np.random.randint(0, len(params[key]))\n",
    "                pp[key] = params[key][ri]\n",
    "            print(pp)\n",
    "            model = self.model(**pp)\n",
    "            scores = cross_val_score(model, X, y, scoring=self.scoring, cv=self.cv, verbose=1, n_jobs=-1)\n",
    "            meanscore = np.mean(np.sqrt(-1*scores))\n",
    "            print(str(pp)+\" \"+str(meanscore))\n",
    "            self.logger.write(str(pp)+\" \"+str(meanscore)+\"\\n\")\n",
    "            self.logger.flush()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves' : list(range(31, 201)),\n",
    "    'max_depth' : [-1,]+list(range(3, 21)),\n",
    "    'learning_rate': [0.05, 0.07, 0.09, 0.1],\n",
    "    'n_estimators': list(range(100, 500)), \n",
    "    'subsample': [float(z)/100 for z in list(range(50, 100))],\n",
    "    'subsample_freq': list(range(0, 10)),\n",
    "    'colsample_bytree':[float(z)/100 for z in list(range(50, 100))],\n",
    "    'min_split_gain': [0, 0.01, 0.02, 0.03, 0.04, 0.05],\n",
    "    'min_child_weight': [0.001, 0.002, 0.003, 0.004, 0.005],\n",
    "    'min_child_samples': [20, 10, 5, 30, 40, 50],\n",
    "    'random_state': [7, 42, 2019, 2020],  \n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "model = LGBMRegressor\n",
    "rs = MyRandomSearch(1000, gfCV5, 'neg_mean_squared_error', model, 'rsp/l2LGBM_N=19.pk', params)\n",
    "rs.fit(l2XTrain, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth' : [3, 4, 5],\n",
    "    'learning_rate': [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1],\n",
    "    'n_estimators': list(range(50, 150)),\n",
    "    'n_jobs': [-1],\n",
    "    'gamma': [0, 0.001, 0.002, 0.003, 0.004],\n",
    "    'max_delta_step': [1,],\n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "model = XGBRegressor\n",
    "rs = MyRandomSearch(1000, gfCV5, 'neg_mean_squared_error', model, 'rsp/l2XGB_N=19.pk', params)\n",
    "rs.fit(l2XTrain, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': list(range(10, 200)),\n",
    "    'max_depth': list(range(5, 20)),\n",
    "    'min_samples_split': list(range(2, 10)),\n",
    "    'min_samples_leaf': list(range(1, 10)),\n",
    "    'max_features': ['sqrt', 'log2']+[float(z)/100 for z in list(range(70, 100))],\n",
    "    'bootstrap': [True, False],\n",
    "    'random_state': list(range(7, 2020)),\n",
    "                      \n",
    "}\n",
    "\n",
    "model = ExtraTreesRegressor\n",
    "rs = MyRandomSearch(1000, gfCV5, 'neg_mean_squared_error', model, 'rsp/l2ET_N=19.pk', params)\n",
    "rs.fit(l2XTrain, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'random_state': list(range(7, 2020)),\n",
    "    'alpha': [1e-4, 1e-4, 1e-3],\n",
    "    'l1_ratio': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.05],\n",
    "    'max_iter': list(range(5, 1000)),\n",
    "    'tol': [1e-5, 1e-4, 1e-3],\n",
    "    'average': [True, True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "model = SGDRegressor\n",
    "\n",
    "scaler = StandardScaler()\n",
    "l2XTrainSc = scaler.fit_transform(l2XTrain)\n",
    "l2XTestSc = scaler.transform(l2XTest)\n",
    "\n",
    "rs = MyRandomSearch(1000, gfCV5, 'neg_mean_squared_error', model, 'rsp/l2ET_N=19.pk', params)\n",
    "rs.fit(l2XTrainSc, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pplgb = {'num_leaves': 114, 'subsample_freq': 4, 'colsample_bytree': 0.54, 'max_depth': 3, 'learning_rate': 0.07, 'min_child_weight': 0.004, 'min_split_gain': 0.05, 'n_estimators': 295, 'subsample': 0.61, 'random_state': 7, 'min_child_samples': 10}\n",
    "ppet = {'bootstrap': False, 'min_samples_leaf': 9, 'n_estimators': 129, 'min_samples_split': 7, 'random_state': 1458, 'max_features': 0.74, 'max_depth': 16}\n",
    "ppsgd = {'l1_ratio': 0.2, 'average': False, 'max_iter': 981, 'penalty': 'l1', 'random_state': 1387, 'tol': 0.001, 'alpha': 0.001}\n",
    "\n",
    "\n",
    "finalModels = [\n",
    "    LGBMRegressor(n_jobs=-1, **pplgb),\n",
    "    XGBRegressor(n_jobs=-1, random_state=7),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('sgd', SGDRegressor(**ppsgd)),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "\n",
    "yPred = np.zeros((len(testDF5),))\n",
    "\n",
    "for model in finalModels:\n",
    "    model.fit(l2XTrain, y1)\n",
    "    yPred += model.predict(l2XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yPred = yPred/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submissionDF = pd.read_csv('dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissionDF['reservation_id'] = testIds1\n",
    "submissionDF['amount_spent_per_room_night_scaled'] = yPred\n",
    "submissionDF.to_csv('submissions/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projects",
   "language": "python",
   "name": "projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
